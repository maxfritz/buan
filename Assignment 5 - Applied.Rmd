---
title: "Assignment 5 - Applied"
author: "Maxwell Fritz"
date: "4/28/2019"
output: pdf_document
---
1.	Tidy and clean your data
```{r eval=FALSE}
install.packages('tidyverse')
install.packages('naniar') 
install.packages('visdat')
install.packages('plyr')
install.packages("caret")
install.packages("e1071")
library('plyr')
library('visdat')
library("tidyverse")
library('naniar')
library('rpart')
library('tree')
library('randomForest')
library('caret')
library('e1071')
library('gridExtra')


#import and look through data
raw <- read.csv(url("https://raw.githubusercontent.com/maxfritz/buan/master/dog_id_max_ranks-Table%201.csv"), header=TRUE, sep=",")

#object.size(raw)
dim(raw)
head(raw) 
summary(raw)

data$Breed <- factor(data$Breed)
data$Dog_Fixed <- factor(data$Dog_Fixed)
data$DNA_Tested <- factor(data$DNA_Tested)
data$Free_Start_User <- factor(data$Free_Start_User)
data$Subscribed <- factor(data$Subscribed)
data$Membership_ID <- factor(data$Membership_ID)

# check for missing values
raw %>%
  miss_var_summary()%>%
  filter(n_miss > 0)

#graph some missing values
missing_values<-sapply(raw, function(x) sum(is.na(x)))
missing_values
missing_df <- data.frame(keyName=names(missing_values), value=missing_values, row.names=NULL)
missing_df %>%
  filter(value>0)
gg_miss_var(raw)+theme_bw()
vis_dat(data)+coord_flip()

# we will omit two empty variables, X and X.1
# in addition, we decided to omit some time label variables that appear to be solely administrative in purpose.
# zip is largely junk and Last_Active_At alone is not useful.
# all variables omitted are:
#           X
#           X.1
#           Mean.ITI..days.
#           Mean.ITI..minutes.
#           Median.ITI..days.
#           Median.ITI..minutes.
#           ZIP
#           Last_Active_At
#           Membership_ID
# and brings our total number of variables to 26.

#variables to drop
drop_vars <- names(raw) %in% c('X','X.1','Mean.ITI..days.','Mean.ITI..minutes.','Median.ITI..days.','Median.ITI..minutes.', 'Zip','Last_Active_At','Membership_ID') 
data <- raw[!drop_vars]

levels(data$Membership_Type)
summary(data$Membership_Type)

# Per data description, data should only include 5 levels for the Membership factor variable.
# Therefore, we exclude those data points with membership values outside of these stated levels (1:5) as erroneous

data <- data %>%
  filter(Membership_Type %in% c(1:5))
summary(data$Membership_Type)

data$Membership_Type <- factor(data$Membership_Type)
summary(data$Membership_Type)

#last data clean
my_data <- data

my_data_filter <- my_data%>%
  filter(Breed != "I Don't Know")%>%
  filter(City != "") %>%
  filter(Country != "")%>%
  filter(State != "")%>%
  filter(City != "N/A") %>%
  filter(Country != "N/A")%>%
  filter(State != "N/A")

my_data_filter$City <- factor(my_data_filter$City)
my_data_filter$Country <- factor(my_data_filter$Country)
my_data_filter$State <- factor(my_data_filter$State)
my_data_filter$Gender <- factor(my_data_filter$Gender)
my_data_filter$Breed <- factor(my_data_filter$Breed)

# Breed has too many factors
length(unique(my_data_filter$Breed))

# Create table showing frequency of each levels occurrence.
table1 <- data.frame(table(my_data_filter$Breed))

# Orders the table in descending order of frequency.
table1 <- table1[order(-table1$Freq),]
table1

# shrink factor levels into top 25 (25 distinct + 2 mislabelled but equivalent pairs)
noChange <- table1$Var1[1:27]
noChange <- factor(noChange)

my_data_filter$Breed <- (ifelse(my_data_filter$Breed %in% noChange, my_data_filter$Breed, "Other")) 

my_data_filter$Breed = factor(my_data_filter$Breed)
length(unique(my_data_filter$Breed))

my_data_filter %>%
  group_by(Breed) %>%
  tally() %>%
  arrange(-n)

# r assigns level integers to char names in a random/unordered format so this will not function every time.
# this is the code we used but note that this won't work. Code still works fine but this lets us access
# dog breed names directly for reference later in the project
my_data_filter$Breed <- revalue(my_data_filter$Breed, 
                                c("723"="Other", 
                                  "736"="Other",
                                  "632"="Labrador Retriever",
                                  "539"="Golden Retriever",
                                  "486"="German Shepherd Dog",
                                  "105"="Australian Shepherd",
                                  "218"="Border Collie",
                                  "789"="Poodle",
                                  "538"="Golden Doodle",
                                  "631"="Labradoodle",
                                  "892"="Shih Tzu",
                                  "657"="Labrador Retriever-Golden Retriever Mix",
                                  "277"="Boxer",
                                  "715"="Miniature Schnauzer",
                                  "883"="Shetland Sheepdog",
                                  "425"="Dachshund",
                                  "145"="Beagle",
                                  "448"="Doberman Pinscher",
                                  "406"="Cockapoo",
                                  "468"="English Springer Spaniel",
                                  "1000"="American Pit Bull Terrier",
                                  "35"="Chihuahua",
                                  "361"="Yorkshire Terrier",
                                  "267"="Boston Terrier",
                                  "580"="Havanese",
                                  "Labrador Retriever-Golden Retriever Mix"="Golden Retriever-Labrador Retriever Mix",
                                  "348"="Cavalier King Charles Spaniel"
                                ))

write.csv(my_data_filter, file = "final_data.csv", row.names = FALSE)
```

2.	Identify one target variable

```{r eval=FALSE}
# Subscription is our target variable.
```

3.	Apply ONE type of method (e.g. logistic regression, decision tree, etc.) to predict your target variable 

```{r eval=FALSE}
#refactors
my_data_filter$Breed <- factor(my_data_filter$Breed)
my_data_filter$Dog_Fixed <- factor(my_data_filter$Dog_Fixed)
my_data_filter$DNA_Tested <- factor(my_data_filter$DNA_Tested)
my_data_filter$Free_Start_User <- factor(my_data_filter$Free_Start_User)
my_data_filter$Subscribed <- factor(my_data_filter$Subscribed)

#train and test
set.seed(6356)
train_ind <- sample(seq_len(nrow(my_data_filter)), size =(floor(0.8 * nrow(my_data_filter))))

train <- my_data_filter[train_ind, ]
test <- my_data_filter[-train_ind, ]
rf1 <-randomForest(Subscribed~Breed_Type+Gender+Breed+Weight+
                    Dog_Fixed+Max_Dogs+Free_Start_User+Breed_Group,
                   data=train,mtry=2,ntree=500)

```

4.	Use cross validation, variable selection methods (e.g., subset selection, the LASSO, etc.) or dimension reduction methods to refine your models, if possible

```{r eval=FALSE}
# model
predict <- predict(rf1,test,type="response")
confusionMatrix(data = test$Subscribed, predict) # 78.84

# random forest algorithm not at risk for overfitting based,
# cross validation on samples is not necessary. 
# Each tree in my beautiful forest is built with the finest OOB sample
# and the remaining data is validated against the tree.

#-----------------------tweak the model?-----------------------

importance <- as.data.frame(as.table(importance(rf1)))
importance <- arrange(importance,-Freq)
importance
# dropping variables based on importance does nothing for our model.
# this could however be used to tune other models.

#-----------------------tweak the model-----------------------

# Our data is very unbalanced in our target variable.
# It might help to tweak our model by building our samples
# by stratifying on our target to ensure that the subgroups
# are adequately represented.
rf2 <-randomForest(Subscribed~Breed_Type+Gender+Breed+Weight+
                    Dog_Fixed+Max_Dogs+Free_Start_User+Breed_Group,
                   data=train,mtry=2,ntree=500,strata=Subscribed) 

predict2 <- predict(rf2,test,type="response")
confusionMatrix(data = test$Subscribed, predict2)
# no change in accuracy but we lost a false positive and gained a false negative.
# since the impact of a type ii is larger for our case, this is not an improvement.

#-----------------------tweak the model-----------------------

# maybe tweaking the cutoff could help reduce our type ii error or improve accuracy.
rf3 <-randomForest(Subscribed~Breed_Type+Gender+Breed+Weight+
                    Dog_Fixed+Max_Dogs+Free_Start_User+Breed_Group,
                   data=train,mtry=2,ntree=500,cutoff = c(0.3,0.7)) 

predict3 <- predict(rf3,test,type="response")
confusionMatrix(data = test$Subscribed, predict3) 
# no improvement. 
# for extreme values we can see a drop of ~6% in accuracy but a small improvement 
# in type ii error which is important for sales.
# overall, not too significant. Cutoff of 1/k is acceptable.

# In addition, above n_trees = 500, improvement is minimal. R crashes at n = 1000,900,800...
# so for the time being, 500 is acceptable. No major improvements expected.
```


5.	Determine which model gives you the best prediction results and present the model with details: which variables are used, the model statistics and performance and interpretations (if possible).

# Selected Model
 rf1 <-randomForest(Subscribed~Breed_Type+Gender+Breed+Weight+
                   Dog_Fixed+Max_Dogs+Free_Start_User+Breed_Group,
                   data=train,mtry=2,ntree=500)

Tuning did little to help. Cutoff of 1/k (0.5,0.5) is best case for this data set.
Stratified sampling of the data does not improve our model.
 
# Confusion Matrix and Statistics

          Reference
 Prediction    0    1
         0   73  459
         1   20 1712
                                         
               Accuracy : 0.7884         
                 95% CI : (0.771, 0.8051)
    No Information Rate : 0.9589         
    P-Value [Acc > NIR] : 1              
                                         
                  Kappa : 0.176          
                                         
 Mcnemar's Test P-Value : <2e-16         
                                         
            Sensitivity : 0.78495        
            Specificity : 0.78858        
         Pos Pred Value : 0.13722        
         Neg Pred Value : 0.98845        
             Prevalence : 0.04108        
         Detection Rate : 0.03224        
   Detection Prevalence : 0.23498        
      Balanced Accuracy : 0.78676  

# Interpretations and implications

Externally, this model provides by far the highest type ii error, which is a major
issue, since the cost of making an erroneous sales call (type i) is much lower than 
the cost of missing a good lead (type ii). In addition, it is not evident by this 
method that many variables are strikingly important. 

The implications of this model, by implementation and in addition to seeing how our tweaks influence
accuracy and type i/ii errors, are that this would not be a great fit for our problem.
